Once the operator is up and running, you can simply create Spark clusters by

# create cluster
cat <<EOF | kubectl create -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-cluster
  labels:
    radanalytics.io/kind: sparkcluster
data:
  config: |-
    workerNodes: "2"
EOF

or in case of CRD approach:

cat <<EOF | kubectl create -f -
apiVersion: radanalytics.io/v1
kind: sparkcluster
metadata:
  name: my-cluster
spec:
  workerNodes: "2"
EOF

For more details consult https://github.com/radanalyticsio/spark-operator/blob/master/README.md
